{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>PDIoT Data Analysis</h1>\n",
    "<p>Hopefully by now you have collected some HAR data. We are asking you to collect data from two sensors - the Respeck (25Hz, accel and gyro) and the Thingy (25Hz, accel, gyro and magnetometer).</p>\n",
    "\n",
    "<p> The Respeck is worn on the lower left ribcage, and the Thingy is worn in the front right pocket of the trousers. </p>\n",
    "\n",
    "<p> We will explore some example data in this notebook. </p>\n",
    "\n",
    "<h3>Accelerometer</h3>\n",
    "<ul>\n",
    "    <li>Measures acceleration (including gravity)</li>\n",
    "    <li>Observing the change in direction of gravity often more useful than linear acceleration due to movement</li>\n",
    "    <li>Sensor values given in g along the axis of interest</li>\n",
    "    <li>Placing our sensor flat on the table should give -1g on the Z axis and 0g on the other axes</li>\n",
    "    <li>Cheap to buy and low power consumption</li>\n",
    "</ul>\n",
    "\n",
    "<h3>Gyroscope</h3>\n",
    "<ul>\n",
    "    <li>Measures angular velocity</li>\n",
    "    <li>Sensor values given in radians per second (deg/sec) along the axis of interest</li>\n",
    "    <li>Placing our sensor flat on the table should give 0 values along all axes</li>\n",
    "    <li>Higher power consumption</li>\n",
    "</ul>\n",
    "\n",
    "<h2>Human Activity Recognition</h2>\n",
    "\n",
    "<p>Your are expected to research and develop the HAR algorithm yourselves during the course. A useful first stage  will be to look at some activity data visually to understand how the sensors react to different types of movement.</p>\n",
    "\n",
    "<p>You are free to use any programming language for the data analysis part of the project, but we recommend using Python and Jupyter Notebook to quickly explore ideas. Below is a simple example using Python/Pandas to graph acceleration data from a sample of walking data.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Tuple\n",
    "# %matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the header"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The files contain a header of size 5. This is where we specify the recording values:\n",
    "- sensor type (Respeck or Thingy)\n",
    "- activity type\n",
    "- activity code (you can find the mapping between activities and their codes in the Constants file on the app)\n",
    "- subject ID (always a student number)\n",
    "- notes (can be empty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filename_respeck = \"./Data/Respeck_s1724067_Lying down left_03-10-2021_16-31-15.csv\"\n",
    "#filename_thingy = \"./Data/Thingy_s1724607_Lying down left_06-10-2021_20-17-30.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'filename_respeck' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_749084/2796952242.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mheader_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename_respeck\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mhead\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'# '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mheader_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhead\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'filename_respeck' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "header_size = 5\n",
    "\n",
    "with open(filename_respeck) as f:\n",
    "    head = [next(f).rstrip().split('# ')[1] for x in range(header_size)]\n",
    "    for l in head:\n",
    "        print(l)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the recording metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's useful to store the metadata about each recording, as you will need it for later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_type = \"\"\n",
    "activity_type = \"\"\n",
    "activity_code = -1\n",
    "subject_id = \"\"\n",
    "notes = \"\"\n",
    "\n",
    "with open(filename_respeck) as f:\n",
    "    head = [next(f).rstrip().split('# ')[1] for x in range(header_size)]\n",
    "    for l in head:\n",
    "        print(l)\n",
    "        \n",
    "        title, value = l.split(\":\")\n",
    "        \n",
    "        if title == \"Sensor type\":\n",
    "            sensor_type = value.strip()\n",
    "        elif title == \"Activity type\":\n",
    "            activity_type = value.strip()\n",
    "        elif title == \"Activity code\":\n",
    "            activity_code = int(value.strip())\n",
    "        elif title == \"Subject id\":\n",
    "            subject_id = value.strip()\n",
    "        elif title == \"Notes\":\n",
    "            notes = value.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might use this later so you can pack it up into a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_header_info(filename: str, header_size: int = 5) -> Tuple[str, str, int, str, str]:\n",
    "    \"\"\"\n",
    "    :param filename: Path to recording file.\n",
    "    :param header_size: The size of the header, defaults to 5.\n",
    "    :returns: A 5-tuple containing the sensor type, activity type, activity code, subject id and any notes.\n",
    "    \"\"\"\n",
    "    sensor_type = \"\"\n",
    "    activity_type = \"\"\n",
    "    activity_code = -1\n",
    "    subject_id = \"\"\n",
    "    notes = \"\"\n",
    "\n",
    "    with open(filename) as f:\n",
    "        head = [next(f).rstrip().split('# ')[1] for x in range(header_size)]\n",
    "        for l in head:\n",
    "            print(l)\n",
    "\n",
    "            title, value = l.split(\":\")\n",
    "\n",
    "            if title == \"Sensor type\":\n",
    "                sensor_type = value.strip()\n",
    "            elif title == \"Activity type\":\n",
    "                activity_type = value.strip()\n",
    "            elif title == \"Activity code\":\n",
    "                activity_code = int(value.strip())\n",
    "            elif title == \"Subject id\":\n",
    "                subject_id = value.strip()\n",
    "            elif title == \"Notes\":\n",
    "                notes = value.strip()\n",
    "    \n",
    "    return sensor_type, activity_type, activity_code, subject_id, notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can get the variables by applying the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_type, activity_type, activity_code, subject_id, notes = extract_header_info(filename=filename_respeck)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can load the file itself using Pandas. You need to specify the amount of rows to be skipped in the beginning (the header size)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_respeck = pd.read_csv(filename_respeck, header=header_size)\n",
    "print(df_respeck)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save the recording metadata for later we can append them as values in new columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_respeck['sensor_type'] = sensor_type\n",
    "df_respeck['activity_type'] = activity_type\n",
    "df_respeck['activity_code'] = activity_code\n",
    "df_respeck['subject_id'] = subject_id\n",
    "df_respeck['notes'] = notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_respeck"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One more important value to save for later is a recording ID. This will be used to split the entire dataset into separate recordings before you start doing any further splitting into windows. The name of the file can act as the unique recording ID for each recording. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_respeck.split(\"/\")[-1].split(\".\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_respeck['recording_id'] = filename_respeck.split(\"/\")[-1].split(\".\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_respeck"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One useful function is checking the frequency of your recordings. The sensors are both running at 25Hz but it is possible that some packets are dropped along the way. You can use the below function to quickly check the frequency of any of your recordings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frequency(dataframe: pd.DataFrame, ts_column: str = 'timestamp') -> float:\n",
    "    \"\"\"\n",
    "    :param dataframe: Dataframe containing sensor data. It needs to have a 'timestamp' column.\n",
    "    :param ts_column: The name of the column containing the timestamps. Default is 'timestamp'.\n",
    "    :returns: Frequency in Hz (samples per second)\n",
    "    \"\"\"\n",
    "\n",
    "    return len(dataframe) / ((dataframe[ts_column].iloc[-1] - dataframe[ts_column].iloc[0]) / 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_respeck_frequency=get_frequency(df_respeck)\n",
    "df_respeck_frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that the frequency of this recording is a bit over 25Hz, which is considered normal. You should be worried if your recordings deviate with more than 2Hz from the 25Hz threshold. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can load the thingy data in a similar way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# extract header information\n",
    "sensor_type, activity_type, activity_code, subject_id, notes = extract_header_info(filename=filename_thingy)\n",
    "\n",
    "# load data\n",
    "df_thingy = pd.read_csv(filename_thingy, header=header_size)\n",
    "\n",
    "# append recording metadata\n",
    "df_thingy['sensor_type'] = sensor_type\n",
    "df_thingy['activity_type'] = activity_type\n",
    "df_thingy['activity_code'] = activity_code\n",
    "df_thingy['subject_id'] = subject_id\n",
    "df_thingy['notes'] = notes\n",
    "\n",
    "# get the recording ID\n",
    "df_thingy['recording_id'] = filename_thingy.split(\"/\")[-1].split(\".\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_thingy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualising data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will learn how to visualise the data from both sensors.\n",
    "\n",
    "Be careful when plotting sensor data, if you are trying to compare activities you need to make sure that the axes match. Accelerometer and Gyroscope data are measured on very different scales - accelerometer data is usually in the range [-4, 4], while gyroscope data can get to the 10s and 100s. You should not plot them on the same plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 1, figsize=(12, 12))\n",
    "\n",
    "# plot respeck\n",
    "ax[0].plot(df_respeck['accel_x'], label=\"accel_x\")\n",
    "ax[0].plot(df_respeck['accel_y'], label=\"accel_y\")\n",
    "ax[0].plot(df_respeck['accel_z'], label=\"accel_z\")\n",
    "ax[0].legend()\n",
    "\n",
    "ax[0].set_title(f\"{df_respeck['sensor_type'].values[0]} - {df_respeck['activity_type'].values[0]} \\n Accelerometer data\")\n",
    "\n",
    "ax[1].plot(df_respeck['gyro_x'], label=\"gyro_x\")\n",
    "ax[1].plot(df_respeck['gyro_y'], label=\"gyro_y\")\n",
    "ax[1].plot(df_respeck['gyro_z'], label=\"gyro_z\")\n",
    "ax[1].legend()\n",
    "\n",
    "ax[1].set_title(f\"{df_respeck['sensor_type'].values[0]} - {df_respeck['activity_type'].values[0]} \\n Gyroscope data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 1, figsize=(12, 18))\n",
    "\n",
    "# plot thingy\n",
    "ax[0].plot(df_thingy['accel_x'], label=\"accel_x\")\n",
    "ax[0].plot(df_thingy['accel_y'], label=\"accel_y\")\n",
    "ax[0].plot(df_thingy['accel_z'], label=\"accel_z\")\n",
    "ax[0].legend()\n",
    "\n",
    "ax[0].set_title(f\"{df_thingy['sensor_type'].values[0]} - {df_thingy['activity_type'].values[0]} \\n Accelerometer data\")\n",
    "\n",
    "ax[1].plot(df_thingy['gyro_x'], label=\"gyro_x\")\n",
    "ax[1].plot(df_thingy['gyro_y'], label=\"gyro_y\")\n",
    "ax[1].plot(df_thingy['gyro_z'], label=\"gyro_z\")\n",
    "ax[1].legend()\n",
    "\n",
    "ax[1].set_title(f\"{df_thingy['sensor_type'].values[0]} - {df_thingy['activity_type'].values[0]} \\n Gyroscope data\")\n",
    "\n",
    "ax[2].plot(df_thingy['mag_x'], label=\"mag_x\")\n",
    "ax[2].plot(df_thingy['mag_y'], label=\"mag_y\")\n",
    "ax[2].plot(df_thingy['mag_z'], label=\"mag_z\")\n",
    "ax[2].legend()\n",
    "\n",
    "ax[2].set_title(f\"{df_thingy['sensor_type'].values[0]} - {df_thingy['activity_type'].values[0]} \\n Magnetometer data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin by visually inspecting a set of different activities for both sensors, to see how they might best be differentiated. Then you can begin to analyse windows of data for the signal and try to categorise it into the different activities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trimming and cleaning data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to visually verify all of your recordings and make sure the activity starts at the very beginning of the recording and stops at the very end. \n",
    "\n",
    "For example, in the above Thingy recording of walking, you can see that the first 25 datapoints (1 second) were rather still, and the real walking begins a second later. You can amend this by trimming the recording to remove the first and last seconds, or however much time you think would work. \n",
    "\n",
    "The total length of your **trimmed and cleaned** recordings should be **30 seconds**.\n",
    "\n",
    "To check the time of a recording (in seconds) you can run the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_thingy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_respeck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_is_25hz(df_respeck,df_thingy):\n",
    "    get_frequency_respeck=get_frequency(df_respeck)\n",
    "    get_frequency_thingy = get_frequency(df_thingy)\n",
    "    if 24<get_frequency_respeck<26 and  24<get_frequency_thingy<26:\n",
    "        return 'No Problem',get_frequency_respeck,get_frequency_thingy\n",
    "    else:\n",
    "        return 'frequency not around 25hz!!!',get_frequency_respeck,get_frequency_thingy\n",
    "data_is_25hz(df_respeck,df_thingy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def found_peak(df):\n",
    "    peak_index = 0\n",
    "    peak_value = max(abs(df['gyro_x'])+abs(df['gyro_y'])+abs(df['gyro_z']))\n",
    "    for i,row in df.iterrows():\n",
    "        if abs(row['gyro_x'])+abs(row['gyro_y'])+abs(row['gyro_z']) == peak_value:\n",
    "            return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_frequency_thingy = get_frequency(df_thingy)\n",
    "get_frequency_respeck=get_frequency(df_respeck)\n",
    "def Get3sData(df_respeck,df_thingy,get_frequency_respeck,get_frequency_thingy):\n",
    "    record_needed_respeck = get_frequency_respeck*3\n",
    "    record_needed_thingy = get_frequency_thingy*3\n",
    "\n",
    "    respeck_front = len(df_respeck)//2 - record_needed_respeck//2\n",
    "    respeck_after = len(df_respeck)//2 + record_needed_respeck//2\n",
    "    thingy_front = len(df_thingy)//2 - record_needed_thingy//2\n",
    "    thingy_after = len(df_thingy)//2 + record_needed_thingy//2\n",
    "    df_respeck_trimmed = df_respeck.iloc[int(respeck_front) :int(respeck_after)]\n",
    "    df_thingy_trimmed = df_thingy.iloc[int(thingy_front):int(thingy_after)]\n",
    "    return df_respeck_trimmed,df_thingy_trimmed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get1sData(df_respeck,df_thingy,get_frequency_respeck,get_frequency_thingy):\n",
    "    record_needed_respeck = get_frequency_respeck+1\n",
    "    record_needed_thingy = get_frequency_thingy+1\n",
    "\n",
    "    respeck_front = found_peak(df_respeck) - record_needed_respeck//2+5\n",
    "    respeck_after = found_peak(df_respeck) + record_needed_respeck//2+5\n",
    "    thingy_front = found_peak(df_thingy) - record_needed_thingy//2+5\n",
    "    thingy_after = found_peak(df_thingy) + record_needed_thingy//2+5\n",
    "    df_respeck_trimmed = df_respeck.iloc[int(respeck_front) :int(respeck_after)]\n",
    "    df_thingy_trimmed = df_thingy.iloc[int(thingy_front):int(thingy_after)]\n",
    "    return df_respeck_trimmed,df_thingy_trimmed\n",
    "df_respeck_trimmed, df_thingy_trimmed = Get1sData(df_respeck,df_thingy,get_frequency_respeck,get_frequency_thingy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#found_peak(df_respeck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_respeck_period=len(df_respeck_trimmed) / get_frequency(df_respeck_trimmed)\n",
    "df_respeck_period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_is_30s(df_respeck_trimmed,df_thingy_trimmed):\n",
    "    df_respeck_period=len(df_respeck_trimmed) / get_frequency(df_respeck_trimmed)\n",
    "    df_thingy_period=len(df_thingy_trimmed) / get_frequency(df_thingy_trimmed)\n",
    "    if 29<df_respeck_period<31 and  29<df_thingy_period<31:\n",
    "        return 'No Problem',df_respeck_period,df_thingy_period\n",
    "    else:\n",
    "        return 'data not around 30s!!!',df_respeck_period,df_thingy_period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_is_30s(df_respeck_trimmed,df_thingy_trimmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_respeck_trimmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_thingy_trimmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outliner_replacement(arr):\n",
    "    dic={}\n",
    "    outliner_list=[]\n",
    "    new_list=[]\n",
    "    elements = np.array(arr)\n",
    "    mean = np.mean(elements, axis=0)\n",
    "    sd = np.std(elements, axis=0)\n",
    "    for x in arr:\n",
    "        if(x < mean - 3 * sd) or (x > mean + 3 * sd):\n",
    "            outliner_list.append(x)\n",
    "            x=mean\n",
    "            new_list.append(x)\n",
    "        else:\n",
    "            new_list.append(x)\n",
    "    for x in outliner_list:\n",
    "        dic[x]=mean\n",
    "    arr = arr.replace(dic)\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df_respeck_trimmed['gyro_x'] = outliner_replacement(df_respeck_trimmed['gyro_x'])\n",
    "#df_respeck_trimmed['gyro_y'] = outliner_replacement(df_respeck_trimmed['gyro_y'])\n",
    "#df_respeck_trimmed['gyro_z'] = outliner_replacement(df_respeck_trimmed['gyro_z'])\n",
    "#df_respeck_trimmed['accel_x'] = outliner_replacement(df_respeck_trimmed['accel_x'])\n",
    "#df_respeck_trimmed['accel_y'] = outliner_replacement(df_respeck_trimmed['accel_y'])\n",
    "#df_respeck_trimmed['accel_z'] = outliner_replacement(df_respeck_trimmed['accel_z'])\n",
    "#df_thingy_trimmed['accel_x'] = outliner_replacement(df_thingy_trimmed['accel_x'])\n",
    "#df_thingy_trimmed['accel_y'] = outliner_replacement(df_thingy_trimmed['accel_y'])\n",
    "#df_thingy_trimmed['accel_z'] = outliner_replacement(df_thingy_trimmed['accel_z'])\n",
    "#df_thingy_trimmed['gyro_x'] = outliner_replacement(df_thingy_trimmed['gyro_x'])\n",
    "#df_thingy_trimmed['gyro_y'] = outliner_replacement(df_thingy_trimmed['gyro_y'])\n",
    "#df_thingy_trimmed['gyro_z'] = outliner_replacement(df_thingy_trimmed['gyro_z'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_respeck_trimmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 1, figsize=(12, 12))\n",
    "\n",
    "# plot respeck\n",
    "ax[0].plot(df_respeck_trimmed['accel_x'], label=\"accel_x\")\n",
    "ax[0].plot(df_respeck_trimmed['accel_y'], label=\"accel_y\")\n",
    "ax[0].plot(df_respeck_trimmed['accel_z'], label=\"accel_z\")\n",
    "ax[0].legend()\n",
    "\n",
    "ax[0].set_title(f\"{df_respeck_trimmed['sensor_type'].values[0]} - {df_respeck_trimmed['activity_type'].values[0]} \\n Accelerometer data\")\n",
    "\n",
    "ax[1].plot(df_respeck_trimmed['gyro_x'], label=\"gyro_x\")\n",
    "ax[1].plot(df_respeck_trimmed['gyro_y'], label=\"gyro_y\")\n",
    "ax[1].plot(df_respeck_trimmed['gyro_z'], label=\"gyro_z\")\n",
    "ax[1].legend()\n",
    "\n",
    "ax[1].set_title(f\"{df_respeck_trimmed['sensor_type'].values[0]} - {df_respeck_trimmed['activity_type'].values[0]} \\n Gyroscope data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 1, figsize=(12, 18))\n",
    "\n",
    "# plot thingy\n",
    "ax[0].plot(df_thingy_trimmed['accel_x'], label=\"accel_x\")\n",
    "ax[0].plot(df_thingy_trimmed['accel_y'], label=\"accel_y\")\n",
    "ax[0].plot(df_thingy_trimmed['accel_z'], label=\"accel_z\")\n",
    "ax[0].legend()\n",
    "\n",
    "ax[0].set_title(f\"{df_thingy_trimmed['sensor_type'].values[0]} - {df_thingy_trimmed['activity_type'].values[0]} \\n Accelerometer data\")\n",
    "\n",
    "ax[1].plot(df_thingy_trimmed['gyro_x'], label=\"gyro_x\")\n",
    "ax[1].plot(df_thingy_trimmed['gyro_y'], label=\"gyro_y\")\n",
    "ax[1].plot(df_thingy_trimmed['gyro_z'], label=\"gyro_z\")\n",
    "ax[1].legend()\n",
    "\n",
    "ax[1].set_title(f\"{df_thingy_trimmed['sensor_type'].values[0]} - {df_thingy_trimmed['activity_type'].values[0]} \\n Gyroscope data\")\n",
    "\n",
    "ax[2].plot(df_thingy_trimmed['mag_x'], label=\"mag_x\")\n",
    "ax[2].plot(df_thingy_trimmed['mag_y'], label=\"mag_y\")\n",
    "ax[2].plot(df_thingy_trimmed['mag_z'], label=\"mag_z\")\n",
    "ax[2].legend()\n",
    "\n",
    "ax[2].set_title(f\"{df_thingy_trimmed['sensor_type'].values[0]} - {df_thingy_trimmed['activity_type'].values[0]} \\n Magnetometer data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving your clean data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you are done cleaning your data you can save it to a location of your choice by running the following commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_respeck_trimmed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_749084/317281922.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrec_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_respeck_trimmed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecording_id\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrec_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdf_respeck_trimmed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"./Data/Clean/{rec_name}.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_respeck_trimmed' is not defined"
     ]
    }
   ],
   "source": [
    "rec_name = df_respeck_trimmed.recording_id.values[0]\n",
    "print(rec_name)\n",
    "\n",
    "df_respeck_trimmed.to_csv(f\"./Data/Clean/{rec_name}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_thingy_trimmed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_749084/1177994909.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrec_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_thingy_trimmed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecording_id\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrec_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdf_thingy_trimmed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"./Data/Clean/{rec_name}.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_thingy_trimmed' is not defined"
     ]
    }
   ],
   "source": [
    "rec_name = df_thingy_trimmed.recording_id.values[0]\n",
    "print(rec_name)\n",
    "\n",
    "df_thingy_trimmed.to_csv(f\"./Data/Clean/{rec_name}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uploading collected data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The format in which you should save each of your recordings is the format we arrive at in this notebook. That is:\n",
    "- no header\n",
    "- all the header information transformed into column values\n",
    "- column list:\n",
    "    * timestamp\n",
    "    * accel_x, accel_y, accel_z\n",
    "    * gyro_x, gyro_y, gyro_z\n",
    "    * (for Thingy recordings) mag_x, mag_y, mag_z\n",
    "    * sensor_type\n",
    "    * activity_type\n",
    "    * activity_code\n",
    "    * subject_id\n",
    "    * notes\n",
    "    * recording_id\n",
    "    \n",
    "Be very vareful when uploading these to the shared repository and make sure your files are in the correct format. We will be checking your submissions automatically. \n",
    "\n",
    "You can double check the columns of your dataframe by running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_respeck_trimmed.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common techniques to consider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* There are two main ways in which you can tackle this HAR task: using Machine Learning algorithms (Random Forest Classifier (RFC), Clustering, Regression etc), or Deep Learning methods (Convolutional Neural Networks (CNN), Recurrent Neural Networks (RNN) etc).\n",
    "\n",
    "\n",
    "* The most common way to preprocess time series data is to divide it into sliding windows (you can choose how much they overlap).\n",
    "\n",
    "\n",
    "* The sliding windows can then be directly passed to your algorithm (for example the CNN), or you can extract features of the signal from the windows and pass a vector of features to the classification algorithm (for example, a RFC). \n",
    "\n",
    "\n",
    "* Be very careful about splitting the data into training, validation and test sets. Your algorithms will perform extremely well when data is coming from the same subject. You need to test your algorithms with a technique called Leave One Subject Out Cross Validation (LOSOXV) whereby you test your method on data from an unseen subject.\n",
    "\n",
    "The Week 2 - Introduction to Human Activity Recognition lab gives you an overview of these techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
